{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import RAKE\n",
    "import nltk\n",
    "import numpy as np\n",
    "from summa import keywords\n",
    "from string import punctuation\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подобрать корпус\n",
    "\n",
    "В качестве мини-корпуса были выбраны несколько недавних статей с сайта Школы Лингвистики. У них есть теги и список организаций, которые упомянуты в статье.\n",
    "\n",
    "# 2. Разметить КС\n",
    "\n",
    "Критерии:\n",
    "\n",
    "- тэги, которых нет в тексте, удаляются\n",
    "- если новость о мероприятии, добавляется название типа мероприятия (конференция, хакатон) и \"онлайн\", если мероприятие происходит онлайн\n",
    "- если есть определенная научная сфера, которая определяет мероприятие, и эта сфера упоминается в тексте, название добавляется в список КС\n",
    "- места проведения мероприятия и другие задействованные огранизации тоже добавляются в список КС\n",
    "\n",
    "Теперь сделаем так, чтобы было удобно работать с корпусом. Пишем функцию препроцессинга:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()\n",
    "def preprocess(text):\n",
    "    lemmas = []\n",
    "    for t in simple_word_tokenize(text):\n",
    "        lemmas.append(\n",
    "            m.parse(t)[0].normal_form\n",
    "        )\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем корпус:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "kws = []\n",
    "\n",
    "for file in os.listdir(\"corpus\"):\n",
    "    if os.path.splitext(os.path.join(\"corpus\", file))[1] == \".txt\":\n",
    "        with open(os.path.join(\"corpus\", file), encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            texts.append(\"\\n\".join(lines))\n",
    "            kws.append(lines[-1].split(\", \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу препроцессим ключевые слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "kws_preproc = [[preprocess(word) for word in kw_list] for kw_list in kws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['экспедиция', 'шетнево', 'макеево', 'деревня', 'селигеро-торжковский говор'],\n",
       " ['поступление',\n",
       "  'магистратура',\n",
       "  'бакалавриат',\n",
       "  'программа',\n",
       "  'образовательный программа',\n",
       "  'ниу вшэ'],\n",
       " ['хакатон', 'цифровой гуманитарный исследование', 'dh', 'онлайн'],\n",
       " ['конференция', 'компьютерный лингвистика', 'школа лингвистика']]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kws_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Применить методы\n",
    "\n",
    "## RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake = RAKE.Rake(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_kw_lists = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    rake_kw_list = rake.run(preprocess(text), maxWords=3, minFrequency=2)\n",
    "    rake_kw_lists.append([elem[0] for elem in rake_kw_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "summa_kw_lists = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    summa_kw_list = keywords.keywords(normalize_text(text),\n",
    "                                      language='russian',\n",
    "                                      additional_stopwords=stop,\n",
    "                                      scores=True)\n",
    "    summa_kw_lists.append([elem[0] for elem in summa_kw_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf.fit_transform([preprocess(text) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf_lists = []\n",
    "for row in tfidf_matrix:\n",
    "    tfidf_kws_ix = np.argsort(row.toarray())[0][:-11:-1]\n",
    "    tfidf_lists.append(np.array(tfidf.get_feature_names())[tfidf_kws_ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Шаблоны\n",
    "\n",
    "## Создаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "kws_flattened = [item for sublist in kws for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tag(text):\n",
    "    postag = \"\"\n",
    "    for t in simple_word_tokenize(text):\n",
    "        if m.parse(t)[0].tag.POS:\n",
    "            postag += m.parse(t)[0].tag.POS+\"+\"\n",
    "    return postag[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "postags = []\n",
    "for elem in kws_flattened:\n",
    "    postags.append(to_tag(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN+NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'ADJF+NOUN',\n",
       " '',\n",
       " 'NOUN',\n",
       " 'ADJF+ADJF+NOUN',\n",
       " '',\n",
       " 'ADVB',\n",
       " 'NOUN',\n",
       " 'ADJF+NOUN',\n",
       " 'NOUN+NOUN']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "postags_unique = set(postags)\n",
    "postags_unique.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJF+ADJF+NOUN', 'ADJF+NOUN', 'ADVB', 'NOUN', 'NOUN+NOUN'}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postags_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фильтруем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_suggestions = [rake_kw_lists,\n",
    "                  summa_kw_lists,\n",
    "                  tfidf_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_suggestions = []\n",
    "for kw_lists in kw_suggestions:\n",
    "    filtered_lists = []\n",
    "    for kw_list in kw_lists:\n",
    "        filtered_list = list(filter(lambda x: to_tag(x) in postags_unique,\n",
    "                                    kw_list))\n",
    "        filtered_lists.append(filtered_list)\n",
    "    filtered_suggestions.append(filtered_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['селигеро-торжковский говор',\n",
       "   'смоленский говор',\n",
       "   'иной житель',\n",
       "   'деревня шетнево',\n",
       "   'деревня',\n",
       "   'дом',\n",
       "   'кличка',\n",
       "   'шетнево',\n",
       "   'озеро',\n",
       "   'обед',\n",
       "   'экспедиция',\n",
       "   'информант',\n",
       "   'почему',\n",
       "   'макеево',\n",
       "   'поэтому',\n",
       "   'семья',\n",
       "   'прозвище',\n",
       "   'поколение',\n",
       "   'целое'],\n",
       "  ['вступительный испытание',\n",
       "   'результат егэ',\n",
       "   'подача документ',\n",
       "   'бюджетный место',\n",
       "   'санкт-петербург',\n",
       "   'нижний новгород',\n",
       "   'русский язык',\n",
       "   'прошлое год',\n",
       "   'английский язык',\n",
       "   'программа',\n",
       "   'вышка',\n",
       "   'онлайн',\n",
       "   'конкурс',\n",
       "   '2022 год',\n",
       "   '2021 год',\n",
       "   '« магистр',\n",
       "   'бакалавриат',\n",
       "   'зачисление',\n",
       "   'поступление',\n",
       "   'магистратура',\n",
       "   '20 июнь',\n",
       "   'е',\n",
       "   'математика',\n",
       "   'число',\n",
       "   'москва',\n",
       "   '« кибербезопасность »',\n",
       "   'наука'],\n",
       "  ['цифровой гуманитарный исследование'],\n",
       "  ['конференция', 'эссе']],\n",
       " [['кличка',\n",
       "   'диалектологический экспедиция',\n",
       "   'мочь',\n",
       "   'говор',\n",
       "   'время',\n",
       "   'местный житель',\n",
       "   'макеево',\n",
       "   'особенно',\n",
       "   'особенность',\n",
       "   'деревня шетнево',\n",
       "   'запись',\n",
       "   'случай',\n",
       "   'кура',\n",
       "   'отец',\n",
       "   'человек',\n",
       "   'дом',\n",
       "   'группа',\n",
       "   'роман',\n",
       "   'ронький',\n",
       "   'количество информант',\n",
       "   'обед',\n",
       "   'отдельно',\n",
       "   'часы',\n",
       "   'разный фамилия',\n",
       "   'руководитель',\n",
       "   'употребление',\n",
       "   'мало',\n",
       "   'почему',\n",
       "   'участник',\n",
       "   'тема',\n",
       "   'первое',\n",
       "   'голова',\n",
       "   'солнце',\n",
       "   'фонд',\n",
       "   'денис'],\n",
       "  ['программа',\n",
       "   'москва',\n",
       "   'приём',\n",
       "   'обучение',\n",
       "   'конкурс',\n",
       "   'количество',\n",
       "   'результат',\n",
       "   'управление',\n",
       "   'балл',\n",
       "   'магистратура',\n",
       "   'мочь',\n",
       "   'бакалавриат',\n",
       "   'направление',\n",
       "   'олимпиада',\n",
       "   'подача документ',\n",
       "   'онлайн',\n",
       "   'вступительный испытание',\n",
       "   'август',\n",
       "   'бизнес',\n",
       "   'июль',\n",
       "   'срок',\n",
       "   'очно',\n",
       "   'проект',\n",
       "   'система',\n",
       "   'экономика',\n",
       "   'средство',\n",
       "   'вышка',\n",
       "   'зачисление',\n",
       "   'призёр',\n",
       "   'язык',\n",
       "   'достижение',\n",
       "   'кампус',\n",
       "   'стоимость',\n",
       "   'предмет',\n",
       "   'организация',\n",
       "   'экзамен',\n",
       "   'аналитика',\n",
       "   'магистр'],\n",
       "  ['хакатон',\n",
       "   'исследование',\n",
       "   'презентация',\n",
       "   'участник',\n",
       "   'команда',\n",
       "   'целое',\n",
       "   'цель',\n",
       "   'новое',\n",
       "   'интересно',\n",
       "   'человек',\n",
       "   'участие',\n",
       "   'корпус',\n",
       "   'нии',\n",
       "   'торжественно',\n",
       "   'минута',\n",
       "   'глубоко',\n",
       "   'работа',\n",
       "   'онлайн',\n",
       "   'здравоохранение',\n",
       "   'текст',\n",
       "   'область знание',\n",
       "   'культура',\n",
       "   'медиа',\n",
       "   'тысяча',\n",
       "   'исследователь',\n",
       "   'центр'],\n",
       "  ['конференция',\n",
       "   'анна',\n",
       "   'доклад',\n",
       "   'школа лингвистика',\n",
       "   'несколько',\n",
       "   'студент',\n",
       "   'е',\n",
       "   'университет',\n",
       "   'участие',\n",
       "   'студентка',\n",
       "   'язык']],\n",
       " [['экспедиция', 'кличка', 'деревня', 'житель', 'говор', 'шетнево'],\n",
       "  ['программа',\n",
       "   'приём',\n",
       "   'абитуриент',\n",
       "   'место',\n",
       "   'документ',\n",
       "   'год',\n",
       "   'москва',\n",
       "   'бакалавриат'],\n",
       "  ['хакатон',\n",
       "   'исследование',\n",
       "   'команда',\n",
       "   'презентация',\n",
       "   'гуманитарный исследование'],\n",
       "  ['конференция',\n",
       "   'лингвистика',\n",
       "   'доклад',\n",
       "   'анна',\n",
       "   'выступление',\n",
       "   'компьютерный лингвистика',\n",
       "   'эссе',\n",
       "   'студент']]]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Оценить точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fscore(prec, rec):\n",
    "    return 2 * prec * rec / (prec + rec)\n",
    "\n",
    "scores = []\n",
    "for sugg in filtered_suggestions:\n",
    "    algo_score = []\n",
    "    for i, kws in enumerate(sugg):\n",
    "        overall_kws = list(filter(lambda x: x in kws_preproc[i], kws))\n",
    "        precision = len(overall_kws)/len(kws)\n",
    "        recall = len(overall_kws)/len(kws_preproc[i])\n",
    "        algo_score.append((precision,\n",
    "                           recall,\n",
    "                           fscore(precision, recall)))\n",
    "    scores.append(algo_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores = np.array(scores).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method\tprec\trec\tf-score\n",
      "RAKE\t0.478\t0.562\t0.365\n",
      "SUMMA\t0.092\t0.467\t0.151\n",
      "TFIDF\t0.300\t0.463\t0.354\n"
     ]
    }
   ],
   "source": [
    "methods = (\"RAKE\", \"SUMMA\", \"TFIDF\")\n",
    "print(\"method\\tprec\\trec\\tf-score\")\n",
    "for i, row in enumerate(mean_scores):\n",
    "    print(f\"{methods[i]}\\t{row[0]:.3f}\\t{row[1]:.3f}\\t{row[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По F-score лучше всего оказывается RAKE, дальше -- TfIdf и потом с огромным отрывом -- TextRank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Почему так?\n",
    "\n",
    "Скорее всего, алгоритм, основанный на встречаемости с другими словами в данном случае работает слабее, чем алгоритм, основанный на простой частотности слова. Сами тексты не достаточно разнообразны для того, чтобы можно было считать слово более \"ключевым\" в связи с тем, что с ним встречается больше других слов и фраз. Многие изначально обозначенные ключевые слова встречаются всего два раза.\n",
    "\n",
    "Но также можно винить и изначальную разметку, основанную на интуиции, а не на математических подсчетах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made by nejenek"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
